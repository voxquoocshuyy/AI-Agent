# Task T1.4: Chatbot Integration
**Status:** New
**Sprint:** 1
**Priority:** High
**Assigned To:** TBD

## Description
Tích hợp chatbot với Azure OpenAI và Semantic Kernel để xử lý câu hỏi của người dùng và tìm kiếm thông tin từ vector database.

## Technical Details

### 1. Chatbot Architecture
```
AI.Agent/
└── src/
    └── AI.Agent.API/
        └── Chatbot/
            ├── Interfaces/
            │   ├── IChatService.cs
            │   └── IConversationManager.cs
            ├── Services/
            │   ├── ChatService.cs
            │   └── ConversationManager.cs
            ├── Models/
            │   ├── ChatMessage.cs
            │   └── ChatResponse.cs
            └── Configuration/
                └── ChatOptions.cs
```

### 2. Core Implementation
```csharp
// Chat Service Interface
public interface IChatService
{
    Task<ChatResponse> ProcessMessageAsync(string message, string conversationId);
    Task<IEnumerable<ChatMessage>> GetConversationHistoryAsync(string conversationId);
}

// Using Semantic Kernel
public class ChatService : IChatService
{
    private readonly Kernel _kernel;
    private readonly IVectorStore _vectorStore;
    
    public async Task<ChatResponse> ProcessMessageAsync(string message, string conversationId)
    {
        // Create semantic function for RAG
        var ragFunction = _kernel.CreateFunctionFromPrompt(
            @"You are an AI assistant that helps users find information from documents.
            Use the following context to answer the question:
            {{$context}}
            
            Question: {{$input}}
            Answer: ");

        // Get relevant documents
        var queryEmbedding = await _embeddingGenerator.GenerateEmbeddingAsync(message);
        var relevantDocs = await _vectorStore.SearchAsync(queryEmbedding);

        // Create context from relevant documents
        var context = string.Join("\n", relevantDocs.Select(d => d.Content));

        // Execute RAG function
        var result = await _kernel.InvokeAsync(ragFunction, new()
        {
            ["context"] = context,
            ["input"] = message
        });

        return new ChatResponse
        {
            Message = result.ToString(),
            Sources = relevantDocs.Select(d => d.Metadata)
        };
    }
}
```

### 3. Semantic Kernel Configuration
1. **Kernel Setup**
```csharp
var builder = Kernel.CreateBuilder();
builder.AddAzureOpenAIChatCompletion(
    "gpt-4",
    "your-endpoint",
    "your-key");
builder.AddAzureOpenAITextEmbeddingGeneration(
    "text-embedding-ada-002",
    "your-endpoint",
    "your-key");
var kernel = builder.Build();
```

2. **RAG Implementation**
- Document retrieval using vector search
- Context window management
- Prompt engineering for better responses
- Source attribution and citation

## Subtasks

### 1. Chat Service Implementation [Estimation: 5 hours]
- [ ] Setup Semantic Kernel
- [ ] Implement IChatService
- [ ] Add conversation management
- [ ] Add unit tests

### 2. RAG Integration [Estimation: 4 hours]
- [ ] Implement document retrieval
- [ ] Add context management
- [ ] Optimize prompts
- [ ] Add source attribution
- [ ] Add unit tests

### 3. API Endpoints [Estimation: 3 hours]
- [ ] Create chat endpoints
- [ ] Add conversation history endpoints
- [ ] Implement error handling
- [ ] Add API documentation
- [ ] Add integration tests

### 4. Performance & Monitoring [Estimation: 2 hours]
- [ ] Add response caching
- [ ] Implement rate limiting
- [ ] Add telemetry
- [ ] Add performance tests

## Dependencies
- T1.1 (Project Setup)
- T1.2 (Document Processing)
- T1.3 (Vector Database)
- Azure OpenAI Service access

## Acceptance Criteria
- [ ] Successfully processes user messages
- [ ] Provides accurate and relevant responses
- [ ] Maintains conversation context
- [ ] Includes source attribution
- [ ] Unit tests pass with >90% coverage
- [ ] Integration tests pass
- [ ] API documentation is complete

## Notes
- Implement proper error handling
- Add rate limiting to prevent abuse
- Monitor token usage and costs
- Consider implementing streaming responses
- Add proper logging for debugging

## Updated Estimation
- Original: 2 days
- New: 1.75 days (14 hours)
  - Chat Service Implementation: 5 hours
  - RAG Integration: 4 hours
  - API Endpoints: 3 hours
  - Performance & Monitoring: 2 hours 